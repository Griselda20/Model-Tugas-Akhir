nohup: ignoring input
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/timm/models/features.py:4: FutureWarning: Importing from timm.models.features is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/timm/models/hub.py:4: FutureWarning: Importing from timm.models.hub is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
Training with a single process on 1 device (cuda:0).
Model mobile_former_294m created, param count:11422648
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
Created AdamW (AdamW) optimizer: lr: 0.001, betas: (0.9, 0.999), eps: 1e-08, weight_decay: 0.05, amsgrad: False, foreach: None, maximize: False, capturable: False
AMP not enabled. Training in torch.float32.
Restoring model state from checkpoint...
Restoring optimizer state from checkpoint...
Loaded checkpoint '/home/tasi2425111/for_hpc/baru/i_mf/6_new_final_train/output/train/20250402-143114-mobile_former_294m-224/checkpoint-13.pth.tar' (epoch 13)
Scheduled epochs: 300 (epochs + cooldown_epochs). Warmup within epochs when warmup_prefix=False. LR stepped per epoch.
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 16, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 24, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 24, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 48, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 48, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 48, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 48, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 96, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 96, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 96, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 96, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 192, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 192, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
L2G: 2 heads, inp: 192, token: 192
MobileFormer(
  (tokens): Embedding(6, 192)
  (stem): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (features): Sequential(
    (0): DnaBlock3(
      (conv): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Sequential()
        (4): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(16, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=16, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=16, bias=True)
        (proj): Linear(in_features=16, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=192, out_features=24, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (2): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=192, out_features=24, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (3): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(24, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=288, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=192, out_features=48, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (4): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=48, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=192, out_features=48, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (5): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(48, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=576, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=48, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=192, out_features=96, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (6): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=96, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=192, out_features=96, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (7): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1152, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1152, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=96, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (8): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (9): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (10): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=192, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (11): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=192, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
  )
  (local_global): Local2Global(
    (alpha): Sequential(
      (0): Linear(in_features=192, out_features=192, bias=True)
      (1): h_sigmoid(
        (relu): ReLU6(inplace=True)
      )
    )
    (q): Linear(in_features=192, out_features=192, bias=True)
    (proj): Linear(in_features=192, out_features=192, bias=True)
    (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (drop_path): DropPath(drop_prob=0.000)
  )
  (classifier): MergeClassifier(
    (conv): Sequential(
      (0): Sequential()
      (1): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (act): DyReLU(
      (act): ReLU6(inplace=True)
    )
    (hyper): Sequential()
    (avgpool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=(1, 1))
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=1344, out_features=1920, bias=True)
      (1): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.0, inplace=False)
      (1): Linear(in_features=1920, out_features=1000, bias=True)
    )
  )
)
Train: 14 [   0/64058 (  0%)]  Loss: 4.26 (4.26)  Time: 2.286s,    8.75/s  (2.286s,    8.75/s)  LR: 1.139e-05  Data: 0.788 (0.788)  Elapsed/ETA: 2.3s / 146435.8s
Train: 14 [  50/64058 (  0%)]  Loss: 3.98 (5.12)  Time: 0.389s,   51.44/s  (0.436s,   45.91/s)  LR: 1.139e-05  Data: 0.012 (0.026)  Elapsed/ETA: 22.2s / 27881.5s
Train: 14 [ 100/64058 (  0%)]  Loss: 5.63 (5.00)  Time: 0.383s,   52.23/s  (0.413s,   48.45/s)  LR: 1.139e-05  Data: 0.011 (0.018)  Elapsed/ETA: 41.7s / 26400.4s
Train: 14 [ 150/64058 (  0%)]  Loss: 5.32 (4.98)  Time: 0.507s,   39.43/s  (0.408s,   49.06/s)  LR: 1.139e-05  Data: 0.010 (0.016)  Elapsed/ETA: 61.6s / 26053.0s
Train: 14 [ 200/64058 (  0%)]  Loss: 5.75 (5.02)  Time: 0.383s,   52.17/s  (0.404s,   49.53/s)  LR: 1.139e-05  Data: 0.012 (0.014)  Elapsed/ETA: 81.2s / 25786.1s
Train: 14 [ 250/64058 (  0%)]  Loss: 5.63 (5.03)  Time: 0.383s,   52.28/s  (0.400s,   49.97/s)  LR: 1.139e-05  Data: 0.013 (0.014)  Elapsed/ETA: 100.5s / 25540.2s
Train: 14 [ 300/64058 (  0%)]  Loss: 4.50 (5.05)  Time: 0.377s,   53.07/s  (0.397s,   50.34/s)  LR: 1.139e-05  Data: 0.012 (0.013)  Elapsed/ETA: 119.6s / 25329.6s
Train: 14 [ 350/64058 (  1%)]  Loss: 3.82 (5.03)  Time: 0.372s,   53.72/s  (0.395s,   50.69/s)  LR: 1.139e-05  Data: 0.012 (0.013)  Elapsed/ETA: 138.5s / 25133.9s
Train: 14 [ 400/64058 (  1%)]  Loss: 5.47 (5.04)  Time: 0.373s,   53.69/s  (0.392s,   51.03/s)  LR: 1.139e-05  Data: 0.012 (0.013)  Elapsed/ETA: 157.2s / 24950.9s
Train: 14 [ 450/64058 (  1%)]  Loss: 4.81 (5.04)  Time: 0.374s,   53.55/s  (0.390s,   51.29/s)  LR: 1.139e-05  Data: 0.012 (0.013)  Elapsed/ETA: 175.9s / 24801.8s
Train: 14 [ 500/64058 (  1%)]  Loss: 5.75 (5.06)  Time: 0.374s,   53.54/s  (0.388s,   51.51/s)  LR: 1.139e-05  Data: 0.012 (0.013)  Elapsed/ETA: 194.5s / 24675.4s
Train: 14 [ 550/64058 (  1%)]  Loss: 5.87 (5.06)  Time: 0.373s,   53.68/s  (0.387s,   51.71/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 213.1s / 24564.5s
Train: 14 [ 600/64058 (  1%)]  Loss: 5.88 (5.05)  Time: 0.374s,   53.42/s  (0.386s,   51.86/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 231.8s / 24470.4s
Train: 14 [ 650/64058 (  1%)]  Loss: 4.16 (5.04)  Time: 0.374s,   53.48/s  (0.385s,   52.00/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 250.4s / 24387.5s
Train: 14 [ 700/64058 (  1%)]  Loss: 5.43 (5.04)  Time: 0.377s,   53.09/s  (0.384s,   52.09/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 269.1s / 24324.1s
Train: 14 [ 750/64058 (  1%)]  Loss: 6.16 (5.04)  Time: 0.373s,   53.55/s  (0.383s,   52.18/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 287.9s / 24265.2s
Train: 14 [ 800/64058 (  1%)]  Loss: 4.00 (5.03)  Time: 0.373s,   53.64/s  (0.383s,   52.27/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 306.5s / 24203.3s
Train: 14 [ 850/64058 (  1%)]  Loss: 5.14 (5.03)  Time: 0.372s,   53.82/s  (0.382s,   52.36/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 325.1s / 24145.1s
Train: 14 [ 900/64058 (  1%)]  Loss: 4.67 (5.04)  Time: 0.372s,   53.83/s  (0.381s,   52.43/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 343.7s / 24090.9s
Train: 14 [ 950/64058 (  1%)]  Loss: 5.63 (5.04)  Time: 0.372s,   53.75/s  (0.381s,   52.50/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 362.3s / 24040.9s
Train: 14 [1000/64058 (  2%)]  Loss: 5.97 (5.04)  Time: 0.375s,   53.39/s  (0.381s,   52.56/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 380.9s / 23995.5s
Train: 14 [1050/64058 (  2%)]  Loss: 3.89 (5.04)  Time: 0.372s,   53.79/s  (0.380s,   52.61/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 399.5s / 23951.4s
Train: 14 [1100/64058 (  2%)]  Loss: 4.59 (5.04)  Time: 0.372s,   53.78/s  (0.380s,   52.67/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 418.1s / 23908.1s
Train: 14 [1150/64058 (  2%)]  Loss: 5.84 (5.04)  Time: 0.372s,   53.71/s  (0.379s,   52.71/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 436.7s / 23868.0s
Train: 14 [1200/64058 (  2%)]  Loss: 5.45 (5.04)  Time: 0.371s,   53.90/s  (0.379s,   52.75/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 455.3s / 23831.1s
Train: 14 [1250/64058 (  2%)]  Loss: 6.01 (5.04)  Time: 0.373s,   53.60/s  (0.379s,   52.79/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 474.0s / 23796.8s
Train: 14 [1300/64058 (  2%)]  Loss: 4.46 (5.04)  Time: 0.374s,   53.45/s  (0.379s,   52.82/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 492.7s / 23764.6s
Train: 14 [1350/64058 (  2%)]  Loss: 4.07 (5.04)  Time: 0.375s,   53.40/s  (0.379s,   52.84/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 511.4s / 23735.7s
Train: 14 [1400/64058 (  2%)]  Loss: 6.05 (5.04)  Time: 0.373s,   53.62/s  (0.378s,   52.86/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 530.1s / 23706.5s
Train: 14 [1450/64058 (  2%)]  Loss: 6.01 (5.04)  Time: 0.380s,   52.65/s  (0.378s,   52.88/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 548.8s / 23678.1s
Train: 14 [1500/64058 (  2%)]  Loss: 4.49 (5.04)  Time: 0.381s,   52.46/s  (0.378s,   52.91/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 567.4s / 23647.2s
Train: 14 [1550/64058 (  2%)]  Loss: 5.45 (5.04)  Time: 0.376s,   53.22/s  (0.378s,   52.93/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 586.1s / 23619.8s
Train: 14 [1600/64058 (  2%)]  Loss: 6.01 (5.04)  Time: 0.372s,   53.70/s  (0.378s,   52.95/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 604.7s / 23590.2s
Train: 14 [1650/64058 (  3%)]  Loss: 3.94 (5.04)  Time: 0.373s,   53.61/s  (0.378s,   52.98/s)  LR: 1.139e-05  Data: 0.014 (0.012)  Elapsed/ETA: 623.3s / 23560.7s
Train: 14 [1700/64058 (  3%)]  Loss: 4.44 (5.03)  Time: 0.372s,   53.79/s  (0.377s,   53.00/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 641.9s / 23531.5s
Train: 14 [1750/64058 (  3%)]  Loss: 5.14 (5.03)  Time: 0.371s,   53.94/s  (0.377s,   53.02/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 660.5s / 23502.6s
Train: 14 [1800/64058 (  3%)]  Loss: 5.72 (5.04)  Time: 0.372s,   53.77/s  (0.377s,   53.04/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 679.1s / 23475.8s
Train: 14 [1850/64058 (  3%)]  Loss: 6.10 (5.04)  Time: 0.373s,   53.59/s  (0.377s,   53.05/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 697.8s / 23450.4s
Train: 14 [1900/64058 (  3%)]  Loss: 4.20 (5.04)  Time: 0.372s,   53.81/s  (0.377s,   53.07/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 716.4s / 23423.6s
Train: 14 [1950/64058 (  3%)]  Loss: 5.18 (5.04)  Time: 0.371s,   53.96/s  (0.377s,   53.09/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 735.0s / 23396.7s
Train: 14 [2000/64058 (  3%)]  Loss: 5.34 (5.03)  Time: 0.371s,   53.91/s  (0.377s,   53.11/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 753.6s / 23371.0s
Train: 14 [2050/64058 (  3%)]  Loss: 5.80 (5.03)  Time: 0.370s,   54.07/s  (0.376s,   53.12/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 772.2s / 23344.5s
Train: 14 [2100/64058 (  3%)]  Loss: 4.62 (5.03)  Time: 0.370s,   53.99/s  (0.376s,   53.14/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 790.7s / 23318.4s
Train: 14 [2150/64058 (  3%)]  Loss: 5.06 (5.03)  Time: 0.372s,   53.75/s  (0.376s,   53.15/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 809.3s / 23293.3s
Train: 14 [2200/64058 (  3%)]  Loss: 5.04 (5.04)  Time: 0.375s,   53.27/s  (0.376s,   53.17/s)  LR: 1.139e-05  Data: 0.014 (0.012)  Elapsed/ETA: 828.0s / 23269.0s
Train: 14 [2250/64058 (  4%)]  Loss: 5.68 (5.03)  Time: 0.372s,   53.81/s  (0.376s,   53.18/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 846.6s / 23244.7s
Train: 14 [2300/64058 (  4%)]  Loss: 5.89 (5.04)  Time: 0.374s,   53.53/s  (0.376s,   53.19/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 865.2s / 23220.7s
Train: 14 [2350/64058 (  4%)]  Loss: 4.93 (5.04)  Time: 0.372s,   53.74/s  (0.376s,   53.20/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 883.8s / 23197.9s
Train: 14 [2400/64058 (  4%)]  Loss: 5.01 (5.04)  Time: 0.372s,   53.83/s  (0.376s,   53.21/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 902.5s / 23174.7s
Train: 14 [2450/64058 (  4%)]  Loss: 3.68 (5.04)  Time: 0.371s,   53.88/s  (0.376s,   53.22/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 921.1s / 23151.2s
Train: 14 [2500/64058 (  4%)]  Loss: 5.43 (5.04)  Time: 0.372s,   53.80/s  (0.376s,   53.23/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 939.7s / 23127.8s
Train: 14 [2550/64058 (  4%)]  Loss: 4.54 (5.04)  Time: 0.372s,   53.78/s  (0.376s,   53.24/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 958.3s / 23104.9s
Train: 14 [2600/64058 (  4%)]  Loss: 5.37 (5.04)  Time: 0.372s,   53.71/s  (0.376s,   53.25/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 976.9s / 23082.5s
Train: 14 [2650/64058 (  4%)]  Loss: 5.78 (5.04)  Time: 0.372s,   53.75/s  (0.376s,   53.26/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 995.5s / 23060.0s
Train: 14 [2700/64058 (  4%)]  Loss: 3.93 (5.04)  Time: 0.372s,   53.78/s  (0.375s,   53.27/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1014.1s / 23037.8s
Train: 14 [2750/64058 (  4%)]  Loss: 4.28 (5.04)  Time: 0.373s,   53.55/s  (0.375s,   53.27/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1032.8s / 23016.7s
Train: 14 [2800/64058 (  4%)]  Loss: 6.08 (5.04)  Time: 0.373s,   53.61/s  (0.375s,   53.28/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1051.5s / 22995.6s
Train: 14 [2850/64058 (  4%)]  Loss: 5.78 (5.04)  Time: 0.372s,   53.78/s  (0.375s,   53.28/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1070.2s / 22975.0s
Train: 14 [2900/64058 (  5%)]  Loss: 4.20 (5.04)  Time: 0.385s,   51.96/s  (0.375s,   53.29/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1088.9s / 22954.6s
Train: 14 [2950/64058 (  5%)]  Loss: 5.92 (5.03)  Time: 0.371s,   53.84/s  (0.375s,   53.29/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1107.5s / 22934.0s
Train: 14 [3000/64058 (  5%)]  Loss: 5.21 (5.03)  Time: 0.371s,   53.88/s  (0.375s,   53.30/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1126.1s / 22911.0s
Train: 14 [3050/64058 (  5%)]  Loss: 5.30 (5.03)  Time: 0.371s,   53.95/s  (0.375s,   53.31/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1144.7s / 22889.3s
Train: 14 [3100/64058 (  5%)]  Loss: 4.46 (5.03)  Time: 0.370s,   54.11/s  (0.375s,   53.32/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1163.2s / 22866.2s
Train: 14 [3150/64058 (  5%)]  Loss: 4.70 (5.03)  Time: 0.370s,   54.06/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1181.8s / 22842.9s
Train: 14 [3200/64058 (  5%)]  Loss: 4.83 (5.04)  Time: 0.369s,   54.26/s  (0.375s,   53.34/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1200.3s / 22820.1s
Train: 14 [3250/64058 (  5%)]  Loss: 5.82 (5.04)  Time: 0.370s,   54.06/s  (0.375s,   53.35/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 1218.8s / 22797.2s
Train: 14 [3300/64058 (  5%)]  Loss: 4.31 (5.04)  Time: 0.370s,   54.01/s  (0.375s,   53.36/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1237.4s / 22774.3s
Train: 14 [3350/64058 (  5%)]  Loss: 5.24 (5.04)  Time: 0.369s,   54.22/s  (0.375s,   53.37/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1255.9s / 22751.2s
Train: 14 [3400/64058 (  5%)]  Loss: 5.91 (5.03)  Time: 0.370s,   54.03/s  (0.375s,   53.38/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1274.4s / 22728.4s
Train: 14 [3450/64058 (  5%)]  Loss: 6.59 (5.03)  Time: 0.370s,   54.06/s  (0.375s,   53.38/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1292.9s / 22705.8s
Train: 14 [3500/64058 (  5%)]  Loss: 3.56 (5.04)  Time: 0.372s,   53.73/s  (0.375s,   53.39/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 1311.4s / 22683.3s
Train: 14 [3550/64058 (  6%)]  Loss: 4.57 (5.04)  Time: 0.372s,   53.70/s  (0.375s,   53.40/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1330.1s / 22663.3s
Train: 14 [3600/64058 (  6%)]  Loss: 3.74 (5.04)  Time: 0.374s,   53.53/s  (0.375s,   53.40/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 1348.7s / 22642.8s
Train: 14 [3650/64058 (  6%)]  Loss: 5.40 (5.03)  Time: 0.372s,   53.81/s  (0.375s,   53.40/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1367.3s / 22622.5s
Train: 14 [3700/64058 (  6%)]  Loss: 5.70 (5.03)  Time: 0.372s,   53.75/s  (0.374s,   53.41/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1385.9s / 22602.1s
Train: 14 [3750/64058 (  6%)]  Loss: 3.19 (5.03)  Time: 0.373s,   53.57/s  (0.374s,   53.41/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1404.6s / 22583.1s
Train: 14 [3800/64058 (  6%)]  Loss: 5.74 (5.03)  Time: 0.372s,   53.72/s  (0.374s,   53.41/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1423.3s / 22563.6s
Train: 14 [3850/64058 (  6%)]  Loss: 5.03 (5.04)  Time: 0.373s,   53.67/s  (0.374s,   53.41/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1442.0s / 22544.0s
Train: 14 [3900/64058 (  6%)]  Loss: 5.51 (5.04)  Time: 0.374s,   53.52/s  (0.374s,   53.41/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1460.7s / 22524.8s
Train: 14 [3950/64058 (  6%)]  Loss: 4.96 (5.04)  Time: 0.371s,   53.92/s  (0.374s,   53.42/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1479.3s / 22505.2s
Train: 14 [4000/64058 (  6%)]  Loss: 5.07 (5.04)  Time: 0.372s,   53.79/s  (0.374s,   53.42/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 1497.9s / 22484.9s
Train: 14 [4050/64058 (  6%)]  Loss: 5.34 (5.04)  Time: 0.374s,   53.42/s  (0.374s,   53.42/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1516.6s / 22465.0s
Train: 14 [4100/64058 (  6%)]  Loss: 4.86 (5.04)  Time: 0.378s,   52.87/s  (0.374s,   53.43/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1535.2s / 22444.1s
Train: 14 [4150/64058 (  6%)]  Loss: 4.22 (5.04)  Time: 0.376s,   53.25/s  (0.374s,   53.43/s)  LR: 1.139e-05  Data: 0.015 (0.012)  Elapsed/ETA: 1553.7s / 22423.0s
Train: 14 [4200/64058 (  7%)]  Loss: 3.97 (5.04)  Time: 0.372s,   53.81/s  (0.374s,   53.44/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1572.3s / 22401.9s
Train: 14 [4250/64058 (  7%)]  Loss: 4.06 (5.04)  Time: 0.372s,   53.83/s  (0.374s,   53.44/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 1590.8s / 22380.9s
Train: 14 [4300/64058 (  7%)]  Loss: 5.42 (5.03)  Time: 0.369s,   54.15/s  (0.374s,   53.45/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1609.4s / 22360.0s
Train: 14 [4350/64058 (  7%)]  Loss: 4.50 (5.04)  Time: 0.370s,   54.03/s  (0.374s,   53.46/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1627.9s / 22338.9s
Train: 14 [4400/64058 (  7%)]  Loss: 6.01 (5.04)  Time: 0.372s,   53.82/s  (0.374s,   53.46/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1646.4s / 22318.1s
Train: 14 [4450/64058 (  7%)]  Loss: 5.33 (5.04)  Time: 0.372s,   53.77/s  (0.374s,   53.47/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1665.0s / 22297.2s
Train: 14 [4500/64058 (  7%)]  Loss: 5.06 (5.04)  Time: 0.373s,   53.65/s  (0.374s,   53.47/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1683.5s / 22276.6s
Train: 14 [4550/64058 (  7%)]  Loss: 4.25 (5.04)  Time: 0.371s,   53.84/s  (0.374s,   53.47/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1702.1s / 22256.1s
Train: 14 [4600/64058 (  7%)]  Loss: 3.98 (5.04)  Time: 0.370s,   54.05/s  (0.374s,   53.48/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 1720.7s / 22235.6s
Train: 14 [4650/64058 (  7%)]  Loss: 4.06 (5.04)  Time: 0.370s,   54.05/s  (0.374s,   53.48/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1739.2s / 22214.9s
Train: 14 [4700/64058 (  7%)]  Loss: 5.19 (5.04)  Time: 0.370s,   54.07/s  (0.374s,   53.49/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1757.8s / 22194.3s
Train: 14 [4750/64058 (  7%)]  Loss: 6.24 (5.04)  Time: 0.371s,   53.97/s  (0.374s,   53.49/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1776.3s / 22174.0s
Train: 14 [4800/64058 (  7%)]  Loss: 5.73 (5.04)  Time: 0.372s,   53.83/s  (0.374s,   53.50/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1794.9s / 22153.5s
Train: 14 [4850/64058 (  8%)]  Loss: 5.59 (5.04)  Time: 0.370s,   54.11/s  (0.374s,   53.50/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1813.4s / 22132.7s
Train: 14 [4900/64058 (  8%)]  Loss: 6.36 (5.04)  Time: 0.372s,   53.82/s  (0.374s,   53.51/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1832.0s / 22112.4s
Train: 14 [4950/64058 (  8%)]  Loss: 5.05 (5.04)  Time: 0.369s,   54.21/s  (0.374s,   53.51/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1850.5s / 22092.0s
Train: 14 [5000/64058 (  8%)]  Loss: 5.82 (5.04)  Time: 0.377s,   53.08/s  (0.374s,   53.49/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1869.7s / 22079.9s
Train: 14 [5050/64058 (  8%)]  Loss: 5.75 (5.04)  Time: 0.377s,   53.11/s  (0.374s,   53.47/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1889.1s / 22069.4s
Train: 14 [5100/64058 (  8%)]  Loss: 4.38 (5.04)  Time: 0.386s,   51.81/s  (0.374s,   53.43/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 1909.6s / 22070.7s
Train: 14 [5150/64058 (  8%)]  Loss: 4.98 (5.04)  Time: 0.412s,   48.53/s  (0.375s,   53.39/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1929.6s / 22067.1s
Train: 14 [5200/64058 (  8%)]  Loss: 3.82 (5.04)  Time: 0.378s,   52.91/s  (0.375s,   53.36/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1949.3s / 22059.0s
Train: 14 [5250/64058 (  8%)]  Loss: 4.43 (5.04)  Time: 0.445s,   44.98/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 1969.3s / 22054.4s
Train: 14 [5300/64058 (  8%)]  Loss: 6.12 (5.04)  Time: 0.396s,   50.50/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 1988.1s / 22036.1s
Train: 14 [5350/64058 (  8%)]  Loss: 4.78 (5.04)  Time: 0.373s,   53.62/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 2006.9s / 22017.7s
Train: 14 [5400/64058 (  8%)]  Loss: 5.34 (5.04)  Time: 0.372s,   53.75/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 2025.5s / 21997.8s
Train: 14 [5450/64058 (  9%)]  Loss: 5.81 (5.04)  Time: 0.373s,   53.57/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 2044.2s / 21978.3s
Train: 14 [5500/64058 (  9%)]  Loss: 5.02 (5.04)  Time: 0.372s,   53.82/s  (0.375s,   53.33/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 2062.8s / 21958.3s
Train: 14 [5550/64058 (  9%)]  Loss: 5.53 (5.04)  Time: 0.376s,   53.22/s  (0.375s,   53.31/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2082.4s / 21948.0s
Train: 14 [5600/64058 (  9%)]  Loss: 4.69 (5.04)  Time: 0.486s,   41.16/s  (0.375s,   53.27/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2102.9s / 21947.8s
Train: 14 [5650/64058 (  9%)]  Loss: 3.72 (5.04)  Time: 0.381s,   52.45/s  (0.376s,   53.24/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2122.9s / 21942.0s
Train: 14 [5700/64058 (  9%)]  Loss: 4.66 (5.04)  Time: 0.382s,   52.40/s  (0.376s,   53.22/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2142.5s / 21931.6s
Train: 14 [5750/64058 (  9%)]  Loss: 4.66 (5.04)  Time: 0.402s,   49.79/s  (0.376s,   53.19/s)  LR: 1.139e-05  Data: 0.013 (0.012)  Elapsed/ETA: 2162.6s / 21925.4s
Train: 14 [5800/64058 (  9%)]  Loss: 5.09 (5.04)  Time: 0.381s,   52.51/s  (0.376s,   53.15/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2182.9s / 21921.9s
Train: 14 [5850/64058 (  9%)]  Loss: 4.80 (5.04)  Time: 0.402s,   49.74/s  (0.376s,   53.12/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2202.9s / 21914.5s
Train: 14 [5900/64058 (  9%)]  Loss: 4.02 (5.04)  Time: 0.378s,   52.97/s  (0.377s,   53.09/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2222.8s / 21907.1s
Train: 14 [5950/64058 (  9%)]  Loss: 5.70 (5.04)  Time: 0.384s,   52.02/s  (0.377s,   53.09/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2242.0s / 21891.5s
Train: 14 [6000/64058 (  9%)]  Loss: 5.84 (5.04)  Time: 0.377s,   53.00/s  (0.377s,   53.06/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2261.9s / 21882.8s
Train: 14 [6050/64058 (  9%)]  Loss: 3.94 (5.04)  Time: 0.379s,   52.76/s  (0.377s,   53.04/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2281.6s / 21871.8s
Train: 14 [6100/64058 ( 10%)]  Loss: 4.16 (5.04)  Time: 0.386s,   51.84/s  (0.377s,   53.03/s)  LR: 1.139e-05  Data: 0.017 (0.012)  Elapsed/ETA: 2300.8s / 21856.2s
Train: 14 [6150/64058 ( 10%)]  Loss: 6.02 (5.04)  Time: 0.375s,   53.38/s  (0.377s,   53.02/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2320.1s / 21841.8s
Train: 14 [6200/64058 ( 10%)]  Loss: 5.54 (5.04)  Time: 0.374s,   53.50/s  (0.377s,   53.01/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2339.5s / 21828.0s
Train: 14 [6250/64058 ( 10%)]  Loss: 5.21 (5.04)  Time: 0.466s,   42.94/s  (0.377s,   52.98/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2359.6s / 21820.4s
Train: 14 [6300/64058 ( 10%)]  Loss: 5.98 (5.04)  Time: 0.387s,   51.68/s  (0.378s,   52.95/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2379.9s / 21814.5s
Train: 14 [6350/64058 ( 10%)]  Loss: 5.22 (5.04)  Time: 0.391s,   51.21/s  (0.378s,   52.92/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2400.2s / 21808.7s
Train: 14 [6400/64058 ( 10%)]  Loss: 4.58 (5.04)  Time: 0.378s,   52.87/s  (0.378s,   52.89/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2420.3s / 21801.0s
Train: 14 [6450/64058 ( 10%)]  Loss: 5.09 (5.04)  Time: 0.383s,   52.18/s  (0.378s,   52.87/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2440.5s / 21793.5s
Train: 14 [6500/64058 ( 10%)]  Loss: 5.30 (5.04)  Time: 0.377s,   53.11/s  (0.378s,   52.85/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2460.3s / 21782.5s
Train: 14 [6550/64058 ( 10%)]  Loss: 5.45 (5.04)  Time: 0.389s,   51.37/s  (0.379s,   52.81/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2480.8s / 21777.2s
Train: 14 [6600/64058 ( 10%)]  Loss: 4.14 (5.04)  Time: 0.426s,   47.00/s  (0.379s,   52.80/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2500.4s / 21764.6s
Train: 14 [6650/64058 ( 10%)]  Loss: 5.40 (5.04)  Time: 0.382s,   52.40/s  (0.379s,   52.78/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2520.2s / 21753.1s
Train: 14 [6700/64058 ( 10%)]  Loss: 5.64 (5.05)  Time: 0.382s,   52.37/s  (0.379s,   52.76/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2540.1s / 21742.0s
Train: 14 [6750/64058 ( 11%)]  Loss: 5.62 (5.04)  Time: 0.379s,   52.81/s  (0.379s,   52.74/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2560.3s / 21733.9s
Train: 14 [6800/64058 ( 11%)]  Loss: 5.53 (5.04)  Time: 0.385s,   51.90/s  (0.379s,   52.71/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2580.3s / 21723.5s
Train: 14 [6850/64058 ( 11%)]  Loss: 4.16 (5.04)  Time: 0.380s,   52.57/s  (0.379s,   52.71/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2599.4s / 21705.6s
Train: 14 [6900/64058 ( 11%)]  Loss: 4.17 (5.04)  Time: 0.384s,   52.06/s  (0.380s,   52.69/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2619.5s / 21695.6s
Train: 14 [6950/64058 ( 11%)]  Loss: 5.84 (5.04)  Time: 0.384s,   52.05/s  (0.380s,   52.67/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2639.5s / 21685.2s
Train: 14 [7000/64058 ( 11%)]  Loss: 4.27 (5.04)  Time: 0.386s,   51.81/s  (0.380s,   52.63/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2660.5s / 21682.3s
Train: 14 [7050/64058 ( 11%)]  Loss: 4.04 (5.04)  Time: 0.374s,   53.52/s  (0.380s,   52.61/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2680.4s / 21671.2s
Train: 14 [7100/64058 ( 11%)]  Loss: 4.13 (5.04)  Time: 0.377s,   52.99/s  (0.380s,   52.60/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2700.1s / 21657.3s
Train: 14 [7150/64058 ( 11%)]  Loss: 4.67 (5.04)  Time: 0.375s,   53.26/s  (0.380s,   52.60/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2719.2s / 21639.5s
Train: 14 [7200/64058 ( 11%)]  Loss: 4.35 (5.04)  Time: 0.385s,   51.91/s  (0.380s,   52.59/s)  LR: 1.139e-05  Data: 0.012 (0.012)  Elapsed/ETA: 2738.6s / 21622.9s
Train: 14 [7250/64058 ( 11%)]  Loss: 5.44 (5.04)  Time: 0.378s,   52.88/s  (0.380s,   52.57/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2758.9s / 21614.0s
Train: 14 [7300/64058 ( 11%)]  Loss: 4.54 (5.04)  Time: 0.375s,   53.32/s  (0.381s,   52.56/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2778.3s / 21597.9s
Train: 14 [7350/64058 ( 11%)]  Loss: 3.81 (5.04)  Time: 0.454s,   44.06/s  (0.381s,   52.54/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2798.5s / 21588.0s
Train: 14 [7400/64058 ( 12%)]  Loss: 4.83 (5.04)  Time: 0.377s,   53.11/s  (0.381s,   52.52/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2818.2s / 21574.4s
Train: 14 [7450/64058 ( 12%)]  Loss: 4.76 (5.04)  Time: 0.526s,   38.01/s  (0.381s,   52.47/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2839.9s / 21575.5s
Train: 14 [7500/64058 ( 12%)]  Loss: 5.27 (5.04)  Time: 0.388s,   51.58/s  (0.381s,   52.45/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2860.2s / 21565.5s
Train: 14 [7550/64058 ( 12%)]  Loss: 3.91 (5.04)  Time: 0.391s,   51.14/s  (0.381s,   52.43/s)  LR: 1.139e-05  Data: 0.011 (0.012)  Elapsed/ETA: 2880.4s / 21555.1s
Train: 14 [7600/64058 ( 12%)]  Loss: 5.46 (5.04)  Time: 0.420s,   47.61/s  (0.382s,   52.42/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2900.2s / 21541.7s
Train: 14 [7650/64058 ( 12%)]  Loss: 5.47 (5.04)  Time: 0.378s,   52.94/s  (0.382s,   52.40/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2920.4s / 21530.8s
Train: 14 [7700/64058 ( 12%)]  Loss: 3.84 (5.04)  Time: 0.379s,   52.72/s  (0.382s,   52.39/s)  LR: 1.139e-05  Data: 0.009 (0.012)  Elapsed/ETA: 2940.1s / 21516.4s
Train: 14 [7750/64058 ( 12%)]  Loss: 5.84 (5.04)  Time: 0.385s,   51.92/s  (0.382s,   52.36/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2960.6s / 21507.0s
Train: 14 [7800/64058 ( 12%)]  Loss: 5.44 (5.04)  Time: 0.384s,   52.07/s  (0.382s,   52.34/s)  LR: 1.139e-05  Data: 0.010 (0.012)  Elapsed/ETA: 2980.7s / 21495.1s
