nohup: ignoring input
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/timm/models/features.py:4: FutureWarning: Importing from timm.models.features is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/timm/models/hub.py:4: FutureWarning: Importing from timm.models.hub is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/tasi2425111/venvmaestro/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Training with a single process on 1 device (cuda:1).
Model modification_294m created, param count:11103020
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
	crop_mode: center
Created AdamW (AdamW) optimizer: lr: 0.001, betas: (0.9, 0.999), eps: 1e-08, weight_decay: 0.05, amsgrad: False, foreach: None, maximize: False, capturable: False
AMP not enabled. Training in torch.float32.
Restoring model state from checkpoint...
Restoring optimizer state from checkpoint...
Loaded checkpoint '/home/tasi2425111/for_hpc/baru/ti_mod/4_new_train/output/train/20250404-095610-modification_294m-224/checkpoint-49.pth.tar' (epoch 49)
Scheduled epochs: 300 (epochs + cooldown_epochs). Warmup within epochs when warmup_prefix=False. LR stepped per epoch.
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 16, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 24, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 24, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 48, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 48, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 48, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 48, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 96, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 96, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 96, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 96, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 192, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 192, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
L2G: 2 heads, inp: 192, token: 192
Modification(
  (tokens): Embedding(6, 192)
  (stem): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (features): Sequential(
    (0): DnaBlock3(
      (conv): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Sequential()
        (4): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(16, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=16, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=16, bias=True)
        (proj): Linear(in_features=16, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=192, out_features=24, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (2): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=192, out_features=24, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (3): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(24, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=288, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=192, out_features=48, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (4): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=48, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=192, out_features=48, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (5): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(48, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=576, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=48, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=192, out_features=96, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (6): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=96, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=192, out_features=96, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (7): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1152, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1152, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=96, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (8): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (9): DnaBlock3(
      (conv1): Sequential(
        (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (10): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=192, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (11): DnaBlock(
      (conv1): Sequential(
        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=192, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU(approximate=none)
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (relative_attn): RelativeAttention(
          (Q): Linear(in_features=192, out_features=192, bias=False)
          (K): Linear(in_features=192, out_features=192, bias=False)
          (V): Linear(in_features=192, out_features=192, bias=False)
          (ff): Linear(in_features=192, out_features=192, bias=True)
          (attn_dropout): Dropout2d(p=0.1, inplace=False)
          (ff_dropout): Dropout(p=0.1, inplace=False)
        )
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
  )
  (local_global): Local2Global(
    (alpha): Sequential(
      (0): Linear(in_features=192, out_features=192, bias=True)
      (1): h_sigmoid(
        (relu): ReLU6(inplace=True)
      )
    )
    (q): Linear(in_features=192, out_features=192, bias=True)
    (proj): Linear(in_features=192, out_features=192, bias=True)
    (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (drop_path): DropPath(drop_prob=0.000)
  )
  (classifier): MergeClassifier(
    (conv): Sequential(
      (0): Sequential()
      (1): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (act): DyReLU(
      (act): ReLU6(inplace=True)
    )
    (hyper): Sequential()
    (avgpool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=(1, 1))
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=1344, out_features=1920, bias=True)
      (1): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.0, inplace=False)
      (1): Linear(in_features=1920, out_features=200, bias=True)
    )
  )
)
Train: 50 [   0/5000 (  0%)]  Loss: 3.84 (3.84)  Time: 2.115s,    9.46/s  (2.115s,    9.46/s)  LR: 1.495e-05  Data: 0.622 (0.622)  Elapsed/ETA: 2.1s / 10574.0s
Train: 50 [  50/5000 (  1%)]  Loss: 3.71 (4.39)  Time: 0.472s,   42.36/s  (0.506s,   39.51/s)  LR: 1.495e-05  Data: 0.009 (0.021)  Elapsed/ETA: 25.8s / 2505.0s
Train: 50 [ 100/5000 (  2%)]  Loss: 4.39 (4.31)  Time: 0.580s,   34.48/s  (0.497s,   40.24/s)  LR: 1.495e-05  Data: 0.010 (0.016)  Elapsed/ETA: 50.2s / 2434.8s
Train: 50 [ 150/5000 (  3%)]  Loss: 4.49 (4.31)  Time: 0.486s,   41.16/s  (0.496s,   40.33/s)  LR: 1.495e-05  Data: 0.017 (0.014)  Elapsed/ETA: 74.9s / 2404.7s
Train: 50 [ 200/5000 (  4%)]  Loss: 4.39 (4.33)  Time: 0.508s,   39.35/s  (0.496s,   40.31/s)  LR: 1.495e-05  Data: 0.010 (0.013)  Elapsed/ETA: 99.7s / 2380.8s
Train: 50 [ 250/5000 (  5%)]  Loss: 4.07 (4.34)  Time: 0.448s,   44.66/s  (0.500s,   40.02/s)  LR: 1.495e-05  Data: 0.010 (0.012)  Elapsed/ETA: 125.4s / 2373.1s
Train: 50 [ 300/5000 (  6%)]  Loss: 4.25 (4.34)  Time: 0.479s,   41.79/s  (0.495s,   40.37/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 149.1s / 2328.2s
Train: 50 [ 350/5000 (  7%)]  Loss: 3.93 (4.34)  Time: 0.439s,   45.52/s  (0.497s,   40.21/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 174.6s / 2312.5s
Train: 50 [ 400/5000 (  8%)]  Loss: 4.17 (4.33)  Time: 0.480s,   41.67/s  (0.500s,   40.00/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 200.5s / 2299.7s
Train: 50 [ 450/5000 (  9%)]  Loss: 3.68 (4.33)  Time: 0.479s,   41.74/s  (0.502s,   39.83/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 226.5s / 2284.4s
Train: 50 [ 500/5000 ( 10%)]  Loss: 4.90 (4.33)  Time: 0.472s,   42.39/s  (0.506s,   39.49/s)  LR: 1.495e-05  Data: 0.010 (0.011)  Elapsed/ETA: 253.7s / 2278.5s
Train: 50 [ 550/5000 ( 11%)]  Loss: 4.63 (4.34)  Time: 0.478s,   41.81/s  (0.505s,   39.64/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 278.0s / 2244.6s
Train: 50 [ 600/5000 ( 12%)]  Loss: 4.78 (4.33)  Time: 0.446s,   44.85/s  (0.504s,   39.68/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 302.9s / 2217.0s
Train: 50 [ 650/5000 ( 13%)]  Loss: 3.49 (4.32)  Time: 0.567s,   35.29/s  (0.504s,   39.66/s)  LR: 1.495e-05  Data: 0.010 (0.011)  Elapsed/ETA: 328.3s / 2193.2s
Train: 50 [ 700/5000 ( 14%)]  Loss: 4.67 (4.33)  Time: 0.579s,   34.51/s  (0.504s,   39.71/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 353.1s / 2165.2s
Train: 50 [ 750/5000 ( 15%)]  Loss: 4.72 (4.32)  Time: 0.541s,   36.97/s  (0.503s,   39.78/s)  LR: 1.495e-05  Data: 0.010 (0.011)  Elapsed/ETA: 377.5s / 2136.1s
Train: 50 [ 800/5000 ( 16%)]  Loss: 3.62 (4.32)  Time: 0.575s,   34.76/s  (0.504s,   39.70/s)  LR: 1.495e-05  Data: 0.010 (0.011)  Elapsed/ETA: 403.5s / 2115.2s
Train: 50 [ 850/5000 ( 17%)]  Loss: 4.56 (4.32)  Time: 0.523s,   38.26/s  (0.503s,   39.76/s)  LR: 1.495e-05  Data: 0.010 (0.011)  Elapsed/ETA: 428.0s / 2086.9s
Train: 50 [ 900/5000 ( 18%)]  Loss: 4.18 (4.33)  Time: 0.443s,   45.19/s  (0.503s,   39.78/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 453.0s / 2061.1s
Train: 50 [ 950/5000 ( 19%)]  Loss: 4.66 (4.33)  Time: 0.487s,   41.08/s  (0.502s,   39.86/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 477.2s / 2031.7s
Train: 50 [1000/5000 ( 20%)]  Loss: 4.36 (4.33)  Time: 0.476s,   42.04/s  (0.501s,   39.95/s)  LR: 1.495e-05  Data: 0.009 (0.011)  Elapsed/ETA: 501.1s / 2002.0s
Train: 50 [1050/5000 ( 21%)]  Loss: 3.91 (4.33)  Time: 0.587s,   34.07/s  (0.499s,   40.07/s)  LR: 1.495e-05  Data: 0.011 (0.011)  Elapsed/ETA: 524.6s / 1971.1s
Train: 50 [1100/5000 ( 22%)]  Loss: 4.12 (4.33)  Time: 0.440s,   45.44/s  (0.497s,   40.21/s)  LR: 1.495e-05  Data: 0.010 (0.011)  Elapsed/ETA: 547.6s / 1939.2s
Train: 50 [1150/5000 ( 23%)]  Loss: 4.68 (4.33)  Time: 0.447s,   44.74/s  (0.497s,   40.26/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 571.8s / 1912.0s
Train: 50 [1200/5000 ( 24%)]  Loss: 4.43 (4.33)  Time: 0.525s,   38.09/s  (0.495s,   40.40/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 594.5s / 1880.6s
Train: 50 [1250/5000 ( 25%)]  Loss: 4.94 (4.33)  Time: 0.477s,   41.94/s  (0.495s,   40.43/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 618.8s / 1854.6s
Train: 50 [1300/5000 ( 26%)]  Loss: 4.11 (4.33)  Time: 0.448s,   44.65/s  (0.493s,   40.54/s)  LR: 1.495e-05  Data: 0.012 (0.010)  Elapsed/ETA: 641.9s / 1825.0s
Train: 50 [1350/5000 ( 27%)]  Loss: 3.87 (4.33)  Time: 0.437s,   45.76/s  (0.492s,   40.64/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 664.8s / 1795.6s
Train: 50 [1400/5000 ( 28%)]  Loss: 4.65 (4.33)  Time: 0.453s,   44.16/s  (0.491s,   40.70/s)  LR: 1.495e-05  Data: 0.014 (0.010)  Elapsed/ETA: 688.5s / 1768.6s
Train: 50 [1450/5000 ( 29%)]  Loss: 4.72 (4.34)  Time: 0.511s,   39.11/s  (0.491s,   40.71/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 712.8s / 1743.4s
Train: 50 [1500/5000 ( 30%)]  Loss: 3.63 (4.34)  Time: 0.445s,   44.98/s  (0.491s,   40.74/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 736.9s / 1717.9s
Train: 50 [1550/5000 ( 31%)]  Loss: 4.45 (4.33)  Time: 0.459s,   43.56/s  (0.490s,   40.82/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 759.9s / 1689.8s
Train: 50 [1600/5000 ( 32%)]  Loss: 4.72 (4.34)  Time: 0.583s,   34.32/s  (0.491s,   40.76/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 785.6s / 1667.8s
Train: 50 [1650/5000 ( 33%)]  Loss: 3.79 (4.34)  Time: 0.440s,   45.50/s  (0.490s,   40.80/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 809.3s / 1641.6s
Train: 50 [1700/5000 ( 34%)]  Loss: 3.81 (4.33)  Time: 0.496s,   40.33/s  (0.489s,   40.87/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 832.5s / 1614.6s
Train: 50 [1750/5000 ( 35%)]  Loss: 4.41 (4.33)  Time: 0.516s,   38.78/s  (0.489s,   40.91/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 855.9s / 1588.2s
Train: 50 [1800/5000 ( 36%)]  Loss: 4.79 (4.33)  Time: 0.445s,   44.96/s  (0.488s,   40.97/s)  LR: 1.495e-05  Data: 0.012 (0.010)  Elapsed/ETA: 879.2s / 1561.7s
Train: 50 [1850/5000 ( 37%)]  Loss: 4.39 (4.34)  Time: 0.442s,   45.20/s  (0.488s,   40.96/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 903.7s / 1537.4s
Train: 50 [1900/5000 ( 38%)]  Loss: 4.12 (4.33)  Time: 0.439s,   45.54/s  (0.488s,   40.97/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 928.0s / 1512.8s
Train: 50 [1950/5000 ( 39%)]  Loss: 4.06 (4.33)  Time: 0.437s,   45.80/s  (0.487s,   41.04/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 950.8s / 1485.9s
Train: 50 [2000/5000 ( 40%)]  Loss: 4.69 (4.33)  Time: 0.484s,   41.34/s  (0.487s,   41.07/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 974.6s / 1460.6s
Train: 50 [2050/5000 ( 41%)]  Loss: 4.83 (4.33)  Time: 0.456s,   43.82/s  (0.486s,   41.12/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 997.6s / 1434.5s
Train: 50 [2100/5000 ( 42%)]  Loss: 4.55 (4.33)  Time: 0.544s,   36.76/s  (0.486s,   41.14/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1021.4s / 1409.4s
Train: 50 [2150/5000 ( 43%)]  Loss: 4.17 (4.33)  Time: 0.438s,   45.65/s  (0.485s,   41.21/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 1044.0s / 1382.7s
Train: 50 [2200/5000 ( 44%)]  Loss: 3.46 (4.33)  Time: 0.524s,   38.17/s  (0.486s,   41.13/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 1070.3s / 1361.0s
Train: 50 [2250/5000 ( 45%)]  Loss: 5.10 (4.33)  Time: 0.476s,   42.04/s  (0.487s,   41.06/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 1096.5s / 1339.1s
Train: 50 [2300/5000 ( 46%)]  Loss: 4.49 (4.33)  Time: 0.475s,   42.13/s  (0.487s,   41.09/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1120.1s / 1313.8s
Train: 50 [2350/5000 ( 47%)]  Loss: 4.69 (4.33)  Time: 0.576s,   34.71/s  (0.487s,   41.04/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1145.7s / 1290.9s
Train: 50 [2400/5000 ( 48%)]  Loss: 4.72 (4.34)  Time: 0.443s,   45.12/s  (0.487s,   41.04/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 1170.1s / 1266.6s
Train: 50 [2450/5000 ( 49%)]  Loss: 3.23 (4.34)  Time: 0.430s,   46.53/s  (0.487s,   41.10/s)  LR: 1.495e-05  Data: 0.011 (0.010)  Elapsed/ETA: 1192.7s / 1240.4s
Train: 50 [2500/5000 ( 50%)]  Loss: 5.02 (4.34)  Time: 0.577s,   34.69/s  (0.487s,   41.07/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1217.8s / 1216.8s
Train: 50 [2550/5000 ( 51%)]  Loss: 3.42 (4.34)  Time: 0.433s,   46.18/s  (0.487s,   41.09/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1241.7s / 1192.1s
Train: 50 [2600/5000 ( 52%)]  Loss: 4.68 (4.34)  Time: 0.427s,   46.89/s  (0.486s,   41.12/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1265.0s / 1166.8s
Train: 50 [2650/5000 ( 53%)]  Loss: 4.57 (4.33)  Time: 0.587s,   34.08/s  (0.486s,   41.13/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1289.2s / 1142.3s
Train: 50 [2700/5000 ( 54%)]  Loss: 4.39 (4.33)  Time: 0.480s,   41.70/s  (0.486s,   41.14/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 1313.0s / 1117.6s
Train: 50 [2750/5000 ( 55%)]  Loss: 3.56 (4.33)  Time: 0.584s,   34.23/s  (0.486s,   41.12/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1338.0s / 1093.9s
Train: 50 [2800/5000 ( 56%)]  Loss: 4.68 (4.33)  Time: 0.433s,   46.20/s  (0.487s,   41.10/s)  LR: 1.495e-05  Data: 0.016 (0.010)  Elapsed/ETA: 1363.1s / 1070.1s
Train: 50 [2850/5000 ( 57%)]  Loss: 5.21 (4.33)  Time: 0.487s,   41.10/s  (0.486s,   41.13/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1386.3s / 1044.9s
Train: 50 [2900/5000 ( 58%)]  Loss: 4.09 (4.33)  Time: 0.467s,   42.79/s  (0.486s,   41.17/s)  LR: 1.495e-05  Data: 0.010 (0.010)  Elapsed/ETA: 1409.3s / 1019.7s
Train: 50 [2950/5000 ( 59%)]  Loss: 4.64 (4.33)  Time: 0.473s,   42.32/s  (0.485s,   41.20/s)  LR: 1.495e-05  Data: 0.009 (0.010)  Elapsed/ETA: 1432.7s / 994.8s
Train: 50 [3000/5000 ( 60%)]  Loss: 4.17 (4.33)  Time: 0.561s,   35.62/s  (0.488s,   40.96/s)  LR: 1.495e-05  Data: 0.009 (0.013)  Elapsed/ETA: 1465.3s / 976.1s
Train: 50 [3050/5000 ( 61%)]  Loss: 4.59 (4.33)  Time: 0.573s,   34.88/s  (0.488s,   40.94/s)  LR: 1.495e-05  Data: 0.009 (0.013)  Elapsed/ETA: 1490.4s / 952.1s
Train: 50 [3100/5000 ( 62%)]  Loss: 3.93 (4.33)  Time: 0.423s,   47.23/s  (0.489s,   40.92/s)  LR: 1.495e-05  Data: 0.009 (0.013)  Elapsed/ETA: 1515.8s / 928.3s
Train: 50 [3150/5000 ( 63%)]  Loss: 4.17 (4.33)  Time: 0.424s,   47.16/s  (0.488s,   40.99/s)  LR: 1.495e-05  Data: 0.009 (0.013)  Elapsed/ETA: 1537.6s / 902.2s
Train: 50 [3200/5000 ( 64%)]  Loss: 4.31 (4.33)  Time: 0.426s,   46.97/s  (0.487s,   41.05/s)  LR: 1.495e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1559.7s / 876.6s
Train: 50 [3250/5000 ( 65%)]  Loss: 4.41 (4.33)  Time: 0.563s,   35.55/s  (0.488s,   41.02/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1585.0s / 852.7s
Train: 50 [3300/5000 ( 66%)]  Loss: 4.07 (4.33)  Time: 0.431s,   46.45/s  (0.487s,   41.06/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1608.0s / 827.6s
Train: 50 [3350/5000 ( 67%)]  Loss: 4.25 (4.33)  Time: 0.427s,   46.87/s  (0.486s,   41.13/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1629.7s / 801.9s
Train: 50 [3400/5000 ( 68%)]  Loss: 4.60 (4.33)  Time: 0.416s,   48.07/s  (0.485s,   41.20/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1650.8s / 776.1s
Train: 50 [3450/5000 ( 69%)]  Loss: 4.75 (4.33)  Time: 0.414s,   48.31/s  (0.484s,   41.29/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1671.7s / 750.3s
Train: 50 [3500/5000 ( 70%)]  Loss: 3.77 (4.33)  Time: 0.416s,   48.13/s  (0.483s,   41.37/s)  LR: 1.495e-05  Data: 0.008 (0.012)  Elapsed/ETA: 1692.6s / 724.7s
Train: 50 [3550/5000 ( 71%)]  Loss: 4.38 (4.34)  Time: 0.417s,   47.99/s  (0.483s,   41.45/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1713.5s / 699.2s
Train: 50 [3600/5000 ( 72%)]  Loss: 3.38 (4.33)  Time: 0.423s,   47.31/s  (0.482s,   41.53/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1734.3s / 673.8s
Train: 50 [3650/5000 ( 73%)]  Loss: 4.66 (4.33)  Time: 0.469s,   42.69/s  (0.481s,   41.56/s)  LR: 1.495e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1756.8s / 649.1s
Train: 50 [3700/5000 ( 74%)]  Loss: 4.48 (4.33)  Time: 0.484s,   41.32/s  (0.481s,   41.56/s)  LR: 1.495e-05  Data: 0.011 (0.012)  Elapsed/ETA: 1781.0s / 625.1s
Train: 50 [3750/5000 ( 75%)]  Loss: 3.83 (4.33)  Time: 0.565s,   35.39/s  (0.481s,   41.54/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1805.9s / 601.3s
Train: 50 [3800/5000 ( 76%)]  Loss: 4.73 (4.33)  Time: 0.466s,   42.93/s  (0.481s,   41.56/s)  LR: 1.495e-05  Data: 0.010 (0.012)  Elapsed/ETA: 1829.1s / 577.0s
Train: 50 [3850/5000 ( 77%)]  Loss: 4.42 (4.33)  Time: 0.429s,   46.64/s  (0.481s,   41.60/s)  LR: 1.495e-05  Data: 0.009 (0.012)  Elapsed/ETA: 1851.6s / 552.4s
